{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a560d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    TapasConfig,\n",
    "    TapasForQuestionAnswering,\n",
    "    TapasTokenizer\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c21eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def _parse_answer_coordinates(coord):\n",
    "    if coord is None or pd.isna(coord):\n",
    "        return []\n",
    "\n",
    "\n",
    "    coord_str = str(coord).strip()\n",
    "\n",
    "    try:\n",
    "        parsed = ast.literal_eval(coord_str)\n",
    "    except Exception:\n",
    "       \n",
    "        coord_str = coord_str.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        if \",\" in coord_str:\n",
    "            r, c = coord_str.split(\",\")\n",
    "            return [(int(r), int(c))]\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "\n",
    "  \n",
    "    if isinstance(parsed, list):\n",
    "        for item in parsed:\n",
    "            # item = (1,2)\n",
    "            if isinstance(item, (tuple, list)):\n",
    "                r, c = item\n",
    "                results.append((int(r), int(c)))\n",
    "\n",
    "            # item = \"(1,2)\"\n",
    "            elif isinstance(item, str):\n",
    "                item = item.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                r, c = item.split(\",\")\n",
    "                results.append((int(r.strip()), int(c.strip())))\n",
    "\n",
    "    elif isinstance(parsed, tuple):\n",
    "        r, c = parsed\n",
    "        results.append((int(r), int(c)))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bded856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, device):\n",
    "    config = TapasConfig.from_pretrained(\n",
    "        \"google/tapas-base-finetuned-wikisql-supervised\"\n",
    "    )\n",
    "\n",
    "    model = TapasForQuestionAnswering.from_pretrained(\n",
    "        \"google/tapas-base\",\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d3fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, dataset, device):\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    correct_cellSelection = 0\n",
    "    correct_aggregationPrediction = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            total += 1\n",
    "\n",
    "            table = pd.read_csv(dataset.iloc[i].table_file, encoding=\"utf-8\").astype(str)\n",
    "            query = dataset.iloc[i].question\n",
    "\n",
    "            inputs = tokenizer(\n",
    "                table=table,\n",
    "                queries=query,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            # ---- GPU forward ----\n",
    "            inputs_gpu = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs_gpu)\n",
    "\n",
    "           \n",
    "            inputs_cpu = {k: v.cpu() for k, v in inputs_gpu.items()}\n",
    "\n",
    "            predicted_answer_coordinates, predicted_aggregation_indices = \\\n",
    "                tokenizer.convert_logits_to_predictions(\n",
    "                    inputs_cpu,\n",
    "                    outputs.logits.detach().cpu(),\n",
    "                    outputs.logits_aggregation.detach().cpu()\n",
    "                )\n",
    "\n",
    "            predicted_answer_coordinates = predicted_answer_coordinates[0]\n",
    "            predicted_aggregation_indices = predicted_aggregation_indices[0]\n",
    "\n",
    "            answer_coordinates_labeled = _parse_answer_coordinates(\n",
    "                dataset.iloc[i].answer_coordinates\n",
    "            )\n",
    "            aggregation_label_labeled = int(dataset.iloc[i].aggregation_label)\n",
    "\n",
    "            if predicted_answer_coordinates == answer_coordinates_labeled:\n",
    "                correct_cellSelection += 1\n",
    "\n",
    "            if predicted_aggregation_indices == aggregation_label_labeled:\n",
    "                correct_aggregationPrediction += 1\n",
    "\n",
    "            if (predicted_answer_coordinates == answer_coordinates_labeled and\n",
    "                predicted_aggregation_indices == aggregation_label_labeled):\n",
    "                correct += 1\n",
    "\n",
    "    return (\n",
    "        correct / total,\n",
    "        correct_cellSelection / total,\n",
    "        correct_aggregationPrediction / total\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d548d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>gpt测试结果</th>\n",
       "      <th>答案</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>position</th>\n",
       "      <th>question</th>\n",
       "      <th>table_file</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>aggregation_label</th>\n",
       "      <th>float_answer</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>澶囨敞aggregation_label涓細\\n0锛歂ONE\\n1锛歋UM\\n2锛欰VERAGE\\n3: COUNT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the elevation of Ground in meters abov...</td>\n",
       "      <td>52Theparade(rvt2017)_floor.csv</td>\n",
       "      <td>['(1, 2)']</td>\n",
       "      <td>['-46.5370539649164']</td>\n",
       "      <td>0</td>\n",
       "      <td>-46.537054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.000</td>\n",
       "      <td>产生幻觉</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How many windows are in the building, do you k...</td>\n",
       "      <td>161210Med_Dent_Clinic_Combined_floor.csv</td>\n",
       "      <td>['(8, 7)', '(9, 7)', '(13, 7)']</td>\n",
       "      <td>['94.0']</td>\n",
       "      <td>1</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the number of stairs on EG?</td>\n",
       "      <td>20170601_Mauer_BmB_floor.csv</td>\n",
       "      <td>['(2, 4)']</td>\n",
       "      <td>['1.0']</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How many stairs are there in 4th Floor?</td>\n",
       "      <td>OfficeBuilding_floor.csv</td>\n",
       "      <td>['(2, 5)']</td>\n",
       "      <td>['5.0']</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How high above the ground is Level 7 in relati...</td>\n",
       "      <td>Learningzonecorentin_floor.csv</td>\n",
       "      <td>['(8, 2)']</td>\n",
       "      <td>['6.823']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.823000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  annotator  gpt测试结果       答案 Unnamed: 4  position  \\\n",
       "0  NaN        NaN      1.0      NaN        NaN       NaN   \n",
       "1  NaN        NaN      0.0  167.000       产生幻觉       NaN   \n",
       "2  NaN        NaN      1.0      NaN        NaN       NaN   \n",
       "3  NaN        NaN      1.0      NaN        NaN       NaN   \n",
       "4  NaN        NaN      0.0    2.965        NaN       NaN   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is the elevation of Ground in meters abov...   \n",
       "1  How many windows are in the building, do you k...   \n",
       "2                What is the number of stairs on EG?   \n",
       "3            How many stairs are there in 4th Floor?   \n",
       "4  How high above the ground is Level 7 in relati...   \n",
       "\n",
       "                                 table_file               answer_coordinates  \\\n",
       "0            52Theparade(rvt2017)_floor.csv                       ['(1, 2)']   \n",
       "1  161210Med_Dent_Clinic_Combined_floor.csv  ['(8, 7)', '(9, 7)', '(13, 7)']   \n",
       "2              20170601_Mauer_BmB_floor.csv                       ['(2, 4)']   \n",
       "3                  OfficeBuilding_floor.csv                       ['(2, 5)']   \n",
       "4            Learningzonecorentin_floor.csv                       ['(8, 2)']   \n",
       "\n",
       "             answer_text  aggregation_label  float_answer  Unnamed: 9  \\\n",
       "0  ['-46.5370539649164']                  0    -46.537054         NaN   \n",
       "1               ['94.0']                  1     94.000000         NaN   \n",
       "2                ['1.0']                  0      1.000000         NaN   \n",
       "3                ['5.0']                  0      5.000000         NaN   \n",
       "4              ['6.823']                  0      6.823000         NaN   \n",
       "\n",
       "   澶囨敞aggregation_label涓細\\n0锛歂ONE\\n1锛歋UM\\n2锛欰VERAGE\\n3: COUNT  label  \n",
       "0                                                NaN            floor  \n",
       "1                                                NaN            floor  \n",
       "2                                                NaN            floor  \n",
       "3                                                NaN            floor  \n",
       "4                                                NaN            floor  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_excel_csv = \"val_data_all.csv\"\n",
    "\n",
    "test_dataset = pd.read_csv(test_excel_csv)\n",
    "\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "test_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a23a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['output_weights', 'aggregation_classifier.bias', 'column_output_bias', 'output_bias', 'aggregation_classifier.weight', 'column_output_weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = r\"C:\\state_dict_model.pt\"\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_PATH, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f36f4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Accuracy: 0.8649\n",
      "Cell Selection Accuracy: 0.9339\n",
      "Aggregation Accuracy: 0.9282\n"
     ]
    }
   ],
   "source": [
    "acc, acc_cell, acc_agg = evaluate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=test_dataset,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Joint Accuracy: {acc:.4f}\")\n",
    "print(f\"Cell Selection Accuracy: {acc_cell:.4f}\")\n",
    "print(f\"Aggregation Accuracy: {acc_agg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8634f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec176f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
